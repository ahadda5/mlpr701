{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4095cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mugariya.farooq/.conda/envs/mine/lib/python3.7/site-packages/robustness/train.py:24: UserWarning: Could not import amp.\n",
      "  warnings.warn('Could not import amp.')\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = '/tmp/'\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "\n",
    "from robustness import model_utils, datasets, train, defaults\n",
    "from robustness.datasets import Xray\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from robustness import data_augmentation as da\n",
    "import torch \n",
    "import torchvision.datasets\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c371398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cox (http://github.com/MadryLab/cox) to log, store and analyze\n",
    "# results. Read more at https//cox.readthedocs.io.\n",
    "from cox.utils import Parameters\n",
    "import cox.store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f91e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "train_transformer = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(.25,.25,.25),\n",
    "            transforms.RandomRotation(2),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transformer = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "batchsize=4\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)   \n",
    "        #sample = {'img': image,\n",
    "               #   'label': int(self.img_list[idx][1])}\n",
    "        return image,int(self.img_list[idx][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a707f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "trainset = CovidCTDataset(root_dir='/home/mugariya.farooq/Downloads/COVID-CT-master/Images-processed/',\n",
    "                              txt_COVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/COVID/trainCT_COVID.txt',\n",
    "                              txt_NonCOVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                              transform= train_transformer)\n",
    "valset = CovidCTDataset(root_dir='/home/mugariya.farooq/Downloads/COVID-CT-master/Images-processed/',\n",
    "                              txt_COVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/COVID/valCT_COVID.txt',\n",
    "                              txt_NonCOVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "testset = CovidCTDataset(root_dir='/home/mugariya.farooq/Downloads/COVID-CT-master/Images-processed/',\n",
    "                              txt_COVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/COVID/testCT_COVID.txt',\n",
    "                              txt_NonCOVID='/home/mugariya.farooq/Downloads/COVID-CT-master/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "                              \n",
    "                              \n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "#print(testset.__len__())\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True,num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=True,num_workers=NUM_WORKERS, pin_memory=True)\n",
    "#test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221ba355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackerModel(\n",
      "  (normalizer): InputNormalize()\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): SequentialWithArgs(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): SequentialWithArgs(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer3): SequentialWithArgs(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer4): SequentialWithArgs(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      "  (attacker): Attacker(\n",
      "    (normalize): InputNormalize()\n",
      "    (model): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer1): SequentialWithArgs(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "      )\n",
      "      (layer2): SequentialWithArgs(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "      )\n",
      "      (layer3): SequentialWithArgs(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "      )\n",
      "      (layer4): SequentialWithArgs(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (shortcut): Sequential()\n",
      "        )\n",
      "      )\n",
      "      (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Logging in: /tmp/55cf222e-8e33-489a-bc42-87ab99a09c6e\n"
     ]
    }
   ],
   "source": [
    "ds = Xray('/tmp/train_xray') # FashionMNIST('/tmp')\n",
    "#dsC= CINIC('/tmp/cinic')\n",
    "#train_loader = torch.utils.data.DataLoader(ds,batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "#val_loader = torch.utils.data.DataLoader(ds,batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "#train_loader = train_loader.to(device='cuda')\n",
    "#val_loader = val_loader.to(device='cuda')\n",
    "\n",
    "m, _ = model_utils.make_and_restore_model(arch='resnet50', dataset=ds)                          \n",
    "input = torch.randn((16,3,224,224))\n",
    "#output = m(input)\n",
    "#print(output)\n",
    "#m.fc =   nn.Linear(in_features=2048, out_features=2, bias=True)   \n",
    "print(m)                \n",
    "# Create a cox store for logging\n",
    "out_store = cox.store.Store(OUT_DIR)\n",
    "\n",
    "# Hard-coded base parameters\n",
    "train_kwargs = {\n",
    "    'out_dir': \"train_out\",\n",
    "    'adv_train': 1,\n",
    "    'constraint': '2',\n",
    "    'eps': 0.5,\n",
    "    'attack_lr': 0.1,\n",
    "    'attack_steps': 7,\n",
    "    'epochs': 150\n",
    "}\n",
    "train_args = Parameters(train_kwargs)\n",
    "\n",
    "# Fill whatever parameters are missing from the defaults\n",
    "train_args = defaults.check_and_fill_args(train_args,\n",
    "                        defaults.TRAINING_ARGS, Xray)\n",
    "train_args = defaults.check_and_fill_args(train_args,\n",
    "                        defaults.PGD_ARGS, Xray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f0e51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch:0 | Loss 17.9723 | AdvPrec1 51.765 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:0 | Loss 0.8735 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 |\n",
      "Val Epoch:0 | Loss 0.9097 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 |\n",
      "Train Epoch:1 | Loss 1.1198 | AdvPrec1 49.176 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:2 | Loss 0.7420 | AdvPrec1 52.706 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:3 | Loss 0.7079 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:4 | Loss 0.7198 | AdvPrec1 51.294 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:5 | Loss 0.7213 | AdvPrec1 54.588 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:5 | Loss 0.7980 | NatPrec1 50.000 | NatPrec5 100.000 | Reg term: 0.0 |\n",
      "Val Epoch:5 | Loss 0.8027 | AdvPrec1 50.000 | AdvPrec5 100.000 | Reg term: 0.0 |\n",
      "Train Epoch:6 | Loss 0.7227 | AdvPrec1 52.941 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:7 | Loss 0.7222 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:8 | Loss 0.6985 | AdvPrec1 55.294 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:9 | Loss 0.7275 | AdvPrec1 48.941 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:10 | Loss 0.7504 | AdvPrec1 50.118 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:10 | Loss 0.7432 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:10 | Loss 0.7436 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:11 | Loss 0.7213 | AdvPrec1 56.471 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:12 | Loss 0.6969 | AdvPrec1 52.000 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:13 | Loss 0.7174 | AdvPrec1 54.588 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:14 | Loss 0.7150 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:15 | Loss 0.7297 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:15 | Loss 0.7081 | NatPrec1 50.000 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:15 | Loss 0.7099 | AdvPrec1 50.000 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:16 | Loss 0.7153 | AdvPrec1 51.765 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:17 | Loss 0.7023 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:18 | Loss 0.7074 | AdvPrec1 56.471 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:19 | Loss 0.7004 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:20 | Loss 0.7521 | AdvPrec1 51.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:20 | Loss 0.7334 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:20 | Loss 0.7337 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:21 | Loss 0.7304 | AdvPrec1 49.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:22 | Loss 0.7451 | AdvPrec1 50.588 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:23 | Loss 0.7143 | AdvPrec1 52.471 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:24 | Loss 0.7088 | AdvPrec1 52.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:25 | Loss 0.7195 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:25 | Loss 0.7264 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:25 | Loss 0.7354 | AdvPrec1 50.000 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:26 | Loss 0.7176 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:27 | Loss 0.7303 | AdvPrec1 49.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:28 | Loss 0.6942 | AdvPrec1 52.000 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:29 | Loss 0.6947 | AdvPrec1 55.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:30 | Loss 0.7063 | AdvPrec1 51.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:30 | Loss 2.2189 | NatPrec1 45.763 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:30 | Loss 2.2389 | AdvPrec1 44.915 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:31 | Loss 0.6943 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:32 | Loss 0.7007 | AdvPrec1 54.824 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:33 | Loss 0.7212 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:34 | Loss 0.7136 | AdvPrec1 51.529 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:35 | Loss 0.7264 | AdvPrec1 51.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:35 | Loss 3.6480 | NatPrec1 50.000 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:35 | Loss 3.6986 | AdvPrec1 50.000 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:36 | Loss 0.7202 | AdvPrec1 46.824 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:37 | Loss 0.7078 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:38 | Loss 0.7499 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:39 | Loss 0.7387 | AdvPrec1 49.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:40 | Loss 0.6963 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:40 | Loss 0.8862 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:40 | Loss 0.8874 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:41 | Loss 0.7289 | AdvPrec1 51.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:42 | Loss 0.7415 | AdvPrec1 49.647 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:43 | Loss 0.7085 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:44 | Loss 0.7243 | AdvPrec1 51.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:45 | Loss 0.7143 | AdvPrec1 51.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:45 | Loss 2.4061 | NatPrec1 45.763 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:45 | Loss 2.4420 | AdvPrec1 45.763 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:46 | Loss 0.7139 | AdvPrec1 50.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:47 | Loss 0.7367 | AdvPrec1 49.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:48 | Loss 0.7089 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:49 | Loss 0.7278 | AdvPrec1 55.294 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:50 | Loss 0.6904 | AdvPrec1 52.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:50 | Loss 0.8957 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:50 | Loss 0.9075 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:51 | Loss 0.6878 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:52 | Loss 0.6910 | AdvPrec1 52.471 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:53 | Loss 0.6910 | AdvPrec1 52.000 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:54 | Loss 0.6827 | AdvPrec1 50.824 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:55 | Loss 0.6854 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:55 | Loss 1.4051 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:55 | Loss 1.4286 | AdvPrec1 50.847 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:56 | Loss 0.6914 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:57 | Loss 0.6868 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:58 | Loss 0.6818 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:59 | Loss 0.6886 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:60 | Loss 0.6878 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:60 | Loss 2.5764 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:60 | Loss 2.6151 | AdvPrec1 47.458 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:61 | Loss 0.6872 | AdvPrec1 52.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:62 | Loss 0.6758 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:63 | Loss 0.6828 | AdvPrec1 53.647 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:64 | Loss 0.6828 | AdvPrec1 54.588 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:65 | Loss 0.6825 | AdvPrec1 55.765 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:65 | Loss 0.6860 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:65 | Loss 0.6867 | AdvPrec1 50.847 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:66 | Loss 0.6805 | AdvPrec1 55.765 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:67 | Loss 0.6903 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:68 | Loss 0.6900 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:69 | Loss 0.6829 | AdvPrec1 52.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:70 | Loss 0.6886 | AdvPrec1 54.824 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:70 | Loss 0.8149 | NatPrec1 50.000 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:70 | Loss 0.8246 | AdvPrec1 50.000 | AdvPrec5 100.000 | Reg term: 0.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch:71 | Loss 0.6882 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:72 | Loss 0.6809 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:73 | Loss 0.6870 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:74 | Loss 0.6842 | AdvPrec1 54.588 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:75 | Loss 0.6814 | AdvPrec1 53.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:75 | Loss 0.8033 | NatPrec1 47.458 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:75 | Loss 0.8141 | AdvPrec1 47.458 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:76 | Loss 0.6957 | AdvPrec1 52.471 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:77 | Loss 0.6808 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:78 | Loss 0.6880 | AdvPrec1 49.882 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:79 | Loss 0.6874 | AdvPrec1 51.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:80 | Loss 0.6853 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:80 | Loss 0.9310 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:80 | Loss 0.9402 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:81 | Loss 0.6860 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:82 | Loss 0.6764 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:83 | Loss 0.6795 | AdvPrec1 52.706 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:84 | Loss 0.6835 | AdvPrec1 53.176 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:85 | Loss 0.6826 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:85 | Loss 2.5022 | NatPrec1 46.610 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:85 | Loss 2.5497 | AdvPrec1 45.763 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:86 | Loss 0.6880 | AdvPrec1 52.941 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:87 | Loss 0.6740 | AdvPrec1 56.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:88 | Loss 0.7023 | AdvPrec1 48.941 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:89 | Loss 0.6716 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:90 | Loss 0.6914 | AdvPrec1 52.706 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:90 | Loss 0.7641 | NatPrec1 47.458 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:90 | Loss 0.7722 | AdvPrec1 47.458 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:91 | Loss 0.6908 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:92 | Loss 0.6832 | AdvPrec1 54.353 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:93 | Loss 0.6899 | AdvPrec1 52.941 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:94 | Loss 0.6855 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:95 | Loss 0.6883 | AdvPrec1 52.235 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Val Epoch:95 | Loss 1.7031 | NatPrec1 51.695 | NatPrec5 100.000 | Reg term: 0.0 \n",
      "Val Epoch:95 | Loss 1.7434 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0 \n",
      "Train Epoch:96 | Loss 0.6772 | AdvPrec1 53.647 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:97 | Loss 0.6803 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:98 | Loss 0.6895 | AdvPrec1 51.765 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:99 | Loss 0.6906 | AdvPrec1 54.824 | AdvPrec5 100.000 | Reg term: 0.\n",
      "Train Epoch:100 | Loss 0.6755 | AdvPrec1 53.412 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:100 | Loss 1.6521 | NatPrec1 45.763 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:100 | Loss 1.6773 | AdvPrec1 45.763 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:101 | Loss 0.6829 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:102 | Loss 0.6808 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:103 | Loss 0.6732 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:104 | Loss 0.6825 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:105 | Loss 0.6809 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:105 | Loss 0.9496 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:105 | Loss 0.9607 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:106 | Loss 0.6812 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:107 | Loss 0.6832 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:108 | Loss 0.6745 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:109 | Loss 0.6797 | AdvPrec1 54.118 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:110 | Loss 0.6847 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:110 | Loss 0.9373 | NatPrec1 50.000 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:110 | Loss 0.9459 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:111 | Loss 0.6822 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:112 | Loss 0.6863 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:113 | Loss 0.6814 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:114 | Loss 0.6812 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:115 | Loss 0.6817 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:115 | Loss 8.3084 | NatPrec1 56.780 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:115 | Loss 8.4303 | AdvPrec1 56.780 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:116 | Loss 0.6863 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:117 | Loss 0.6773 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:118 | Loss 0.6726 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:119 | Loss 0.6811 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:120 | Loss 0.6754 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:120 | Loss 5.3602 | NatPrec1 56.780 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:120 | Loss 5.4419 | AdvPrec1 55.085 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:121 | Loss 0.6772 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:122 | Loss 0.6885 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:123 | Loss 0.6759 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:124 | Loss 0.6843 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:125 | Loss 0.6808 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:125 | Loss 0.8607 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:125 | Loss 0.8740 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:126 | Loss 0.6783 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:127 | Loss 0.6754 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:128 | Loss 0.6814 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:129 | Loss 0.6752 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:130 | Loss 0.6814 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:130 | Loss 1.7695 | NatPrec1 45.763 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:130 | Loss 1.7966 | AdvPrec1 45.763 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:131 | Loss 0.6782 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:132 | Loss 0.6791 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:133 | Loss 0.6806 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:134 | Loss 0.6835 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:135 | Loss 0.6857 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:135 | Loss 0.9373 | NatPrec1 49.153 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:135 | Loss 0.9474 | AdvPrec1 49.153 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:136 | Loss 0.6829 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:137 | Loss 0.6818 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:138 | Loss 0.6723 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:139 | Loss 0.6839 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:140 | Loss 0.6799 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:140 | Loss 1.1959 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:140 | Loss 1.2145 | AdvPrec1 50.847 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:141 | Loss 0.6736 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:142 | Loss 0.6826 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:143 | Loss 0.6842 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch:144 | Loss 0.6849 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:145 | Loss 0.6841 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:145 | Loss 2.2555 | NatPrec1 46.610 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:145 | Loss 2.2959 | AdvPrec1 46.610 | AdvPrec5 100.000 | Reg term: 0.0\n",
      "Train Epoch:146 | Loss 0.6780 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:147 | Loss 0.6814 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:148 | Loss 0.6734 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Train Epoch:149 | Loss 0.6871 | AdvPrec1 55.059 | AdvPrec5 100.000 | Reg term: 0\n",
      "Val Epoch:149 | Loss 1.0732 | NatPrec1 50.847 | NatPrec5 100.000 | Reg term: 0.0\n",
      "Val Epoch:149 | Loss 1.0847 | AdvPrec1 50.847 | AdvPrec5 100.000 | Reg term: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AttackerModel(\n",
       "    (normalizer): InputNormalize()\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): SequentialWithArgs(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer2): SequentialWithArgs(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer3): SequentialWithArgs(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer4): SequentialWithArgs(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    )\n",
       "    (attacker): Attacker(\n",
       "      (normalize): InputNormalize()\n",
       "      (model): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer1): SequentialWithArgs(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "        )\n",
       "        (layer2): SequentialWithArgs(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "        )\n",
       "        (layer3): SequentialWithArgs(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "        )\n",
       "        (layer4): SequentialWithArgs(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (shortcut): Sequential()\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model\n",
    "train.train_model(train_args, m, (train_loader, val_loader), store=out_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
